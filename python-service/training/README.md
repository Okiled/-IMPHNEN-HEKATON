# ğŸ¯ AI Market Pulse - ML Training Pipeline

Production-grade machine learning training system with clean architecture.

## ğŸ—ï¸ Architecture

Built with **SOLID principles** and **design patterns**:

- **Strategy Pattern**: Multiple file processors (CSV, Excel, PDF, DOCX, TXT)
- **Factory Pattern**: Automatic processor selection
- **Template Method**: Base preprocessing workflow
- **Observer Pattern**: Progress tracking and logging
- **Facade Pattern**: High-level service APIs
- **Adapter Pattern**: XGBoost model integration

## ğŸ“ Project Structure
```
training/
â”œâ”€â”€ datasets/              # ğŸ“¥ DROP YOUR FILES HERE
â”‚   â”œâ”€â”€ sales_data.csv
â”‚   â”œâ”€â”€ report.xlsx
â”‚   â””â”€â”€ data.pdf
â”œâ”€â”€ preprocessed/          # ğŸ”„ AUTO-GENERATED (cleaned data)
â”œâ”€â”€ models_output/         # ğŸ¯ AUTO-GENERATED (trained models)
â”œâ”€â”€ logs/                  # ğŸ“ Execution logs
â”œâ”€â”€ core/                  # ğŸ›ï¸ Interfaces & models
â”‚   â”œâ”€â”€ interfaces.py      # Abstract base classes
â”‚   â”œâ”€â”€ models.py          # Data classes
â”‚   â””â”€â”€ exceptions.py      # Custom exceptions
â”œâ”€â”€ processors/            # ğŸ“„ File processors
â”‚   â”œâ”€â”€ base.py            # Base processor (template method)
â”‚   â”œâ”€â”€ csv_processor.py
â”‚   â”œâ”€â”€ excel_processor.py
â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”œâ”€â”€ docx_processor.py
â”‚   â””â”€â”€ text_processor.py
â”œâ”€â”€ services/              # ğŸ›ï¸ Business logic
â”‚   â”œâ”€â”€ preprocessing_service.py
â”‚   â””â”€â”€ training_service.py
â”œâ”€â”€ utils/                 # ğŸ”§ Utilities
â”‚   â”œâ”€â”€ logger.py          # Singleton logger
â”‚   â””â”€â”€ validators.py      # Data validation
â”œâ”€â”€ config.py              # âš™ï¸ Configuration
â”œâ”€â”€ preprocess.py          # ğŸ”„ CLI: Preprocessing
â”œâ”€â”€ train.py               # ğŸ¯ CLI: Training
â””â”€â”€ pipeline.py            # ğŸš€ CLI: Complete pipeline
```

## ğŸ›  Requirements

- Install project deps (includes PDF/DOCX/Excel support):  
  from `python-service/`: `pip install -r requirements.txt`  
  (from `python-service/training/`: `pip install -r ../requirements.txt`)

## ğŸš€ Usage

Run from `python-service/training`:

```bash
# 1) Preprocess raw files dropped in datasets/
python preprocess.py

# 2) Train models from preprocessed data
python train.py

# Or run everything in one go
python pipeline.py
```

## ğŸ“¦ Output

### Preprocessed Data
- Location: `preprocessed/`
- Format: `{original_name}_{product}_cleaned.csv`
- Columns: `date`, `quantity`
- Sorted by date, outliers removed

### Trained Models
- Location: `models_output/`
- Format: `xgboost_{product_id}.pkl`
- Includes: P10, P50, P90 models
- Metadata: `xgboost_{product_id}_metadata.json`

## ğŸ¯ Next Steps

After training, models are ready for:
1. Deployment to production API
2. Forecasting via `forecaster.predict()`
3. Integration with frontend dashboard

## ğŸ¤ Contributing

This codebase follows:
- **SOLID Principles**: Single Responsibility, Open/Closed, etc.
- **Clean Architecture**: Separation of concerns
- **Design Patterns**: Strategy, Factory, Observer, etc.
- **Type Hints**: Full type annotations
- **Documentation**: Comprehensive docstrings

## ğŸ“„ License

MIT License - See LICENSE file
